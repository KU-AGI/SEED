cfg_path: ???
tokenizer_cfg_path: configs/tokenizer/seed_llama_tokenizer_hf.yaml
transform_cfg_path: configs/transform/clip_transform.yaml
model_cfg_path: configs/llm/seed_llama_8b.yaml 
result_file_path: ./logs/precision_test
checkpoint_path:
  model_path: pretrained/seed_tokenizer/seed_quantizer.pt
  diffusion_model_path: stabilityai/stable-diffusion-2-1-unclip
image_save_path: fp16_5000

resume: False
load_weight: False
# weight_path: /home/zheedong/Projects/SEED/logs/seed_FID_test_trained_weight/nsvq_v3
# weight_path: /home/zheedong/Projects/SEED/logs/seed_FID_test_trained_weight/vq2.ckpt
weight_path: None
eval: False

dist:
  n_gpus: 1
  n_nodes: 1

dataset:
  val_config:
    karpathy_file_path: /ssd0/data/coco/annotations/karpathy/dataset_coco_test.json
    root_dir: /ssd0/data/coco/images/val2014
    mode: 'karpathy test'  # Choose from 'karpathy test', 'val 30000'
    start_index: 0
    end_index: None
  num_workers: 8
  shuffle: True
  text_max_length: 128

stage1:
  init: 'SEED'

stage2:
  bypass_codebook: False
  load_diffusion: True
  vq:
    type: 'vq2' # ['vq2', 'ema_vq', nsvq']
    replace_codes: True
    replacement_num_batches: 500
    discarding_threshold: 0.1

experiment:
  seed: 0
  stage: 2
  local_batch_size: 1024
  val_batch_size: 16
  test_split: train
  max_epochs: 1
  deterministic: True

optimizer:
  vit_precision: 'fp16'
  diffusion_precision: 'fp16'
  precision: 'bf16'